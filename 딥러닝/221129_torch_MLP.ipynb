{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sxeX6WJvXeEN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.mlp1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.mlp2 = nn.Linear(hidden_size, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.mlp1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.mlp2(out)\n",
        "        out = self.softmax(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "4mHym-1Ahacs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz6xZb651FBm",
        "outputId": "6c8237d8-4199-4e42-b85e-4d6af6eff719"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 28*28*1 # MNIST 이미지 크기\n",
        "hidden_size = 100\n",
        "num_classes = 10 # 총 클래스 개수\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5Q_TZY11OuR",
        "outputId": "dfa648b8-5aed-446c-d923-9ada8a8fab38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNet(\n",
            "  (mlp1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (mlp2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.rand(1, 28*28).to(device)\n",
        "print('data:',data.shape)\n",
        "\n",
        "pred = model(data)\n",
        "print('pred:',pred)\n",
        "\n",
        "y_hat = pred.argmax(1)\n",
        "print(y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jOVUfqO1lEK",
        "outputId": "335c045a-1b16-48de-97f8-4664c6abf013"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data: torch.Size([1, 784])\n",
            "pred: tensor([[0.1036, 0.1174, 0.1056, 0.1051, 0.0841, 0.1053, 0.0826, 0.0879, 0.0997,\n",
            "         0.1087]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAIYP-3f2Jpn",
        "outputId": "3c79b49f-cf9c-4ba6-e623-b72bf414ce10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 28, 28)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LABV373T2TiS",
        "outputId": "ec16ae05-1a2e-4b78-bd0a-e2640bbf5183"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.5628, -1.9509, -1.2040,  ..., -0.4167, -0.8961, -0.9312],\n",
              "         [ 0.2213, -1.6570, -0.1060,  ...,  0.1331, -1.6802, -0.1847],\n",
              "         [ 0.3695,  2.0508, -0.2727,  ..., -1.8373, -0.3343, -1.7743],\n",
              "         ...,\n",
              "         [-0.0338,  0.9713,  0.1836,  ..., -1.3989,  1.3050,  0.2075],\n",
              "         [ 0.7802, -0.5164,  0.6749,  ..., -0.4272,  0.9590,  0.9469],\n",
              "         [-0.6150,  0.2238, -1.0838,  ..., -0.7383, -1.4740, -0.4260]],\n",
              "\n",
              "        [[-0.7350, -0.1618,  1.0298,  ...,  2.3059, -2.2056,  0.9988],\n",
              "         [-0.9880, -0.1160,  0.2779,  ...,  0.0669,  0.0667, -1.9656],\n",
              "         [ 0.0296, -0.0485,  1.8013,  ...,  1.2469, -0.6278,  1.0681],\n",
              "         ...,\n",
              "         [-1.6991, -0.7992, -0.5076,  ..., -0.2147,  0.2684, -1.1654],\n",
              "         [-0.6070,  1.4928, -1.3382,  ..., -1.7268, -0.6231, -0.6319],\n",
              "         [-0.0803, -0.2175, -0.3891,  ..., -1.3543, -0.0812,  0.8255]],\n",
              "\n",
              "        [[ 2.1894, -1.0788,  0.4165,  ..., -1.3191,  1.1884,  0.5310],\n",
              "         [-0.2050,  0.7123, -0.5929,  ..., -0.2397,  0.8347,  0.1504],\n",
              "         [ 0.8334, -1.7202, -3.0780,  ..., -1.0916,  0.6617,  0.4926],\n",
              "         ...,\n",
              "         [-0.7327, -2.0136, -0.7112,  ...,  0.7687, -0.8808,  2.0073],\n",
              "         [-1.6766,  3.2801,  0.8495,  ..., -1.2342, -0.2815,  0.7034],\n",
              "         [ 0.2075, -0.6319, -1.1723,  ...,  1.2092, -1.2034,  1.9322]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc_layer = nn.Linear(in_features=28*28, out_features=100)\n",
        "x_after_fc = fc_layer(x.reshape(-1, 28*28))\n",
        "print(x_after_fc.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDprjlRH2aLe",
        "outputId": "f545f951-a53e-4b79-dc4c-d0d2fa116ccd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_x = flatten(x)\n",
        "flat_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ynsRWLF2z00",
        "outputId": "f697a351-de02-4175-c3fd-faf969d2abc0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fc_layer = nn.Linear(in_features=1*28*28, out_features=200)\n",
        "x_after_fc = fc_layer(flat_x)\n",
        "print(x_after_fc)\n",
        "\n",
        "torch.Size([3, 200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkuob1PV28dw",
        "outputId": "89de9681-c3b6-446d-ccc9-5fb2ccfe030b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 7.8834e-02, -2.8208e-01, -1.8416e-01,  2.0586e-01,  4.3349e-01,\n",
            "         -6.3971e-01, -4.4755e-01, -7.9621e-01, -4.6753e-01,  4.2442e-01,\n",
            "          2.3321e-01,  9.3187e-02, -5.6064e-02,  3.9012e-01, -6.1363e-01,\n",
            "         -7.3660e-01, -1.1514e+00,  2.2695e-02, -8.9200e-01,  9.8878e-01,\n",
            "         -3.5091e-01,  2.4501e-01, -3.9910e-01, -8.4382e-01,  5.9782e-01,\n",
            "         -7.5069e-01,  1.2278e+00, -7.7996e-02,  1.7950e-01, -4.0382e-01,\n",
            "         -2.0233e-01,  1.9325e-01,  6.9677e-01,  1.1351e+00,  3.9608e-01,\n",
            "         -3.6256e-01, -4.0165e-01,  3.4470e-01, -3.9680e-02,  6.9827e-01,\n",
            "         -2.2079e-01, -5.4196e-01, -1.6981e-01,  1.3684e-01,  4.6476e-03,\n",
            "          1.6004e-01,  5.0928e-01, -2.8371e-01, -6.1520e-01,  4.4792e-02,\n",
            "          6.9076e-01, -8.8155e-03,  8.4843e-01,  1.2092e-01, -2.4637e-01,\n",
            "         -3.9731e-01,  2.8272e-01,  8.1325e-01, -4.8994e-01, -5.2103e-01,\n",
            "          3.5281e-02,  2.6610e-01, -7.7900e-01,  1.3782e+00, -4.2176e-01,\n",
            "         -1.1525e+00, -3.2389e-01, -5.0005e-01, -5.3977e-01,  3.6475e-01,\n",
            "         -2.4036e-01, -8.2272e-01,  6.6945e-02,  4.7373e-01,  9.1087e-02,\n",
            "         -3.2437e-01, -1.7991e-01, -2.6396e-01, -1.0116e+00, -3.1247e-01,\n",
            "          5.4116e-02, -5.8859e-01,  1.0290e-01, -1.4570e-01,  3.7140e-01,\n",
            "         -4.8045e-01,  2.0694e-01, -9.7162e-01, -4.3090e-01,  2.3165e-01,\n",
            "         -5.9523e-02, -2.4209e-01, -2.9872e-01, -7.8171e-02,  3.4161e-01,\n",
            "          1.8050e-01,  1.1028e+00,  5.8435e-01, -4.3840e-01, -1.2553e+00,\n",
            "          4.8021e-01,  3.9492e-01,  4.5496e-01, -9.1170e-01, -3.5669e-01,\n",
            "          4.2862e-01,  3.1063e-01,  6.5151e-01,  4.4306e-01,  1.4523e-01,\n",
            "         -1.3323e-01,  7.4571e-02,  1.2826e-01,  9.2070e-01,  3.1252e-01,\n",
            "         -4.8336e-01, -9.0625e-01, -6.4438e-01,  5.3159e-02,  7.4100e-01,\n",
            "         -5.3870e-02, -5.7795e-01, -1.0665e+00, -1.9288e+00,  1.0689e+00,\n",
            "         -3.6664e-01, -2.7466e-01, -5.6572e-01,  8.7325e-01,  7.7971e-02,\n",
            "         -6.0929e-02,  7.1903e-01, -6.7229e-01, -2.2125e-01,  2.3209e-02,\n",
            "          7.6381e-01,  4.2908e-01, -3.2770e-01, -9.9842e-01, -4.2058e-02,\n",
            "          4.0734e-01,  2.3254e-01,  9.1790e-02,  7.8359e-01,  7.1115e-01,\n",
            "         -3.4695e-01, -9.1012e-02, -1.8543e-01, -1.3938e+00, -4.9386e-01,\n",
            "          4.7354e-02,  3.4891e-01,  1.0467e+00, -2.9515e-01, -7.1928e-01,\n",
            "          4.3272e-01, -1.0281e-01, -5.7883e-01,  6.4598e-02,  1.5442e+00,\n",
            "         -3.5855e-02, -1.0022e+00,  3.5717e-01, -4.6727e-01,  1.1349e-01,\n",
            "          8.2675e-01, -3.0555e-01,  3.9740e-01,  9.3927e-01, -7.0979e-01,\n",
            "         -5.1902e-02,  7.9828e-01,  8.3581e-01,  7.5815e-01, -1.3342e-01,\n",
            "         -2.9621e-01, -4.9080e-01, -8.6157e-01,  8.6199e-02, -2.2737e-01,\n",
            "         -3.8604e-01,  3.7479e-01, -3.7234e-01, -1.5681e-01,  1.6825e-01,\n",
            "          3.4341e-01, -2.3950e-01, -3.3124e-01,  1.7579e-01,  3.1521e-01,\n",
            "         -5.1428e-01,  5.0071e-01, -3.7707e-01, -3.0279e-01,  1.0526e+00,\n",
            "         -1.9178e-01,  1.1069e+00,  1.1985e-01,  4.5429e-02,  1.3142e+00],\n",
            "        [-3.3586e-01, -1.6194e-02,  1.1079e-01, -2.3941e-01,  1.2516e-01,\n",
            "         -5.5074e-01,  6.0918e-02, -3.2590e-01, -4.3095e-01, -1.1843e+00,\n",
            "          4.1474e-01, -5.1521e-01, -1.2246e-01,  5.7692e-01, -5.5889e-01,\n",
            "         -1.0192e-02, -4.4735e-01,  7.2938e-02, -1.9356e-01,  8.0076e-01,\n",
            "          5.7233e-01, -1.1155e-01,  1.5124e-02,  1.3250e-01,  3.0827e-01,\n",
            "          1.3474e-01,  1.2434e+00, -7.5001e-01, -5.3341e-01, -3.9746e-01,\n",
            "         -6.6398e-01,  8.4501e-01,  3.8370e-01, -9.9658e-02,  7.4115e-02,\n",
            "          4.5077e-01,  6.2202e-01, -6.1214e-01,  2.2202e-01, -3.1772e-01,\n",
            "          4.9448e-01,  2.3318e-01,  4.4930e-01,  1.1319e+00,  2.0685e-01,\n",
            "         -1.0884e+00,  3.5963e-01,  9.2417e-01,  4.6664e-01, -5.4054e-01,\n",
            "          2.7337e-01, -8.8620e-02, -4.8238e-01, -9.0301e-01,  7.0644e-01,\n",
            "         -5.0553e-01,  8.9009e-01, -2.2040e-02,  4.6101e-01,  3.2098e-01,\n",
            "         -7.6512e-01,  1.3260e-01,  1.6706e-01,  4.5254e-01, -3.2224e-01,\n",
            "          5.8152e-01,  1.1843e+00,  4.9556e-01, -1.0518e+00, -2.0317e-01,\n",
            "         -9.8389e-02,  9.9064e-01,  3.1269e-01,  5.9879e-01,  1.0106e+00,\n",
            "         -9.3794e-01,  4.3001e-01,  3.9712e-01, -5.0328e-01, -2.5297e-03,\n",
            "         -4.7940e-01,  1.1887e-01,  5.4284e-01,  4.9968e-01,  3.0185e-01,\n",
            "          5.9738e-01, -4.5983e-01, -1.2333e+00,  1.1377e+00, -6.1280e-01,\n",
            "          4.0269e-01, -1.3817e+00, -2.5067e-01,  4.8334e-01,  8.4021e-01,\n",
            "          9.1370e-02, -9.5762e-02,  3.9676e-01,  1.1237e-01, -5.1123e-01,\n",
            "          1.2348e-01, -6.2995e-01,  3.8803e-01, -2.5051e-01,  3.9049e-01,\n",
            "         -8.0266e-01,  7.7961e-02,  2.8660e-01,  2.4589e-01,  3.2462e-01,\n",
            "         -1.2676e-01, -6.7313e-01,  6.5977e-01, -3.6363e-01,  1.4251e-01,\n",
            "          1.0828e+00, -1.1696e+00,  4.8462e-01, -1.0678e-01, -6.8320e-01,\n",
            "         -7.6762e-01, -2.8614e-01, -5.3022e-01, -1.0704e-01, -6.4524e-01,\n",
            "         -3.0660e-01, -5.3818e-01,  9.5707e-01, -2.4551e-01, -4.4055e-01,\n",
            "         -6.5465e-01, -8.0111e-01, -3.4604e-01, -1.9340e-01,  5.3854e-01,\n",
            "          5.5105e-01, -2.9884e-01, -3.9343e-01,  1.5425e-01,  4.5934e-02,\n",
            "          7.1285e-01,  1.5074e-01,  4.5151e-02,  8.9313e-02,  4.1394e-01,\n",
            "          7.7095e-02,  4.0291e-01,  1.2572e-01, -1.3610e-03,  8.8789e-01,\n",
            "         -9.1776e-01, -5.1547e-01,  6.3639e-01, -7.3668e-01,  6.3741e-01,\n",
            "          1.0266e+00, -9.6798e-01, -3.5838e-02, -9.5805e-01, -1.0765e+00,\n",
            "          3.1158e-02, -4.2317e-01,  8.3598e-01,  3.9730e-01,  3.6072e-01,\n",
            "          4.2316e-01,  7.0255e-01, -2.1353e-03,  1.8667e-01, -6.2322e-01,\n",
            "         -3.7711e-01,  2.7501e-01, -6.1813e-01, -9.9952e-01,  2.9019e-01,\n",
            "          5.3945e-01,  6.9848e-01,  9.6153e-01,  1.3408e-02, -5.7322e-01,\n",
            "         -9.7846e-01,  1.6194e-01,  2.6031e-01, -1.0632e+00, -2.4564e-01,\n",
            "          2.7293e-01,  8.7510e-02,  1.2285e+00, -1.6868e-01, -7.5732e-01,\n",
            "         -5.9375e-02,  1.5891e-01,  7.2051e-02, -3.7643e-01, -1.0657e+00,\n",
            "         -2.0097e-01, -1.7847e-01,  9.2691e-01,  2.8217e-01, -8.1657e-01],\n",
            "        [-2.5221e-01, -8.0705e-01,  5.4807e-01, -1.0935e+00, -2.3960e-01,\n",
            "          1.2451e+00, -1.1689e-02,  8.8013e-02, -5.7974e-02, -1.1678e+00,\n",
            "          2.2984e-01,  2.3318e-01,  9.9040e-01, -9.8619e-01, -9.7052e-01,\n",
            "          2.6073e-01,  1.0626e-02,  5.4975e-01,  4.8091e-01,  5.9870e-01,\n",
            "          6.0357e-01, -2.0613e-01, -2.6305e-01, -1.4814e-01,  6.9752e-01,\n",
            "          5.6640e-01, -2.6826e-01,  1.8401e-01,  3.2907e-01,  4.5103e-01,\n",
            "          6.3723e-02,  3.5761e-01, -5.4280e-01,  2.7009e-01,  3.8418e-01,\n",
            "          2.4733e-01, -2.2576e-01,  6.1870e-01,  5.9616e-02, -2.2668e-01,\n",
            "         -1.8360e+00, -4.6740e-01,  1.0658e+00, -2.4621e-01, -1.3126e+00,\n",
            "          4.3251e-01, -5.2311e-01, -7.1622e-01, -3.7150e-01, -2.8399e-01,\n",
            "         -4.4449e-01, -9.3902e-01,  6.1215e-01, -3.7780e-01, -2.9957e-01,\n",
            "          9.7901e-01,  5.3477e-01,  1.5049e-01,  2.2532e-01, -2.5469e-01,\n",
            "         -7.0568e-01, -3.4624e-01, -5.1444e-01,  7.8530e-01,  6.1472e-01,\n",
            "         -1.0551e+00,  7.1605e-01,  4.2214e-01, -1.6131e-01, -8.2491e-01,\n",
            "          4.5584e-01, -2.0240e-01,  4.4793e-03,  3.6216e-01, -3.0622e-02,\n",
            "          7.2849e-01, -1.3628e+00,  1.9003e-01, -6.0861e-01, -2.3078e-01,\n",
            "         -7.8215e-01,  3.8810e-01, -5.1712e-01, -3.2282e-01, -5.1780e-01,\n",
            "         -9.7233e-01, -1.0854e+00,  4.6302e-01,  6.1768e-01,  4.9739e-01,\n",
            "         -1.5081e+00,  1.0458e+00,  4.1969e-01, -4.2090e-01,  4.7565e-01,\n",
            "         -1.3079e-01, -2.9616e-02,  5.1830e-01, -1.4075e-01, -2.0653e-01,\n",
            "         -3.8834e-01, -4.9485e-01,  2.6151e-01, -2.6376e-01,  5.1695e-01,\n",
            "          7.0655e-01,  2.8898e-01,  6.4115e-01,  1.6486e-01, -3.1881e-01,\n",
            "         -4.1707e-01, -6.5484e-01, -1.7243e-01,  3.6162e-01,  6.0726e-03,\n",
            "         -2.6948e-01,  7.8531e-01, -3.0134e-01, -1.6283e-01, -5.9201e-01,\n",
            "         -2.4874e-01, -2.7291e-01,  9.0980e-01,  2.3589e-02, -5.3500e-01,\n",
            "         -7.1339e-01,  5.5081e-01, -1.1121e-01,  8.0036e-02, -5.6831e-01,\n",
            "          1.2972e+00, -1.0087e+00, -5.1581e-01,  6.3668e-01, -3.5044e-01,\n",
            "          1.8642e-01, -1.9623e-01,  2.9448e-01, -1.0597e+00, -3.8253e-01,\n",
            "         -6.7505e-02, -1.5130e-01,  3.8627e-01,  7.3496e-02,  3.3121e-01,\n",
            "         -4.2926e-01, -9.4843e-01, -4.8052e-01, -4.7788e-01,  7.1882e-01,\n",
            "          1.3143e+00, -1.6627e-01,  9.3789e-02, -8.7432e-02,  2.0307e-01,\n",
            "          8.8207e-01, -2.9410e-01,  4.9235e-01,  5.8003e-01, -1.7844e-01,\n",
            "          4.9713e-01, -2.8736e-01, -5.4648e-02, -3.3862e-01,  7.9898e-01,\n",
            "         -5.6397e-01,  1.0155e-02,  5.1419e-01,  2.5188e-01, -1.5437e-01,\n",
            "         -2.3080e-01, -5.0241e-02,  8.2223e-01, -4.7982e-01, -4.7863e-02,\n",
            "          4.6498e-01,  1.1682e+00, -3.9944e-01,  4.9091e-02, -6.8743e-01,\n",
            "          7.7841e-02, -1.3045e-01,  5.3650e-01,  1.6534e-01,  1.8013e-01,\n",
            "          1.0374e-01, -8.8857e-02,  1.7316e-01, -4.6128e-01, -9.2084e-01,\n",
            "          7.1291e-01,  1.6269e+00, -3.4419e-01,  2.9345e-01,  1.4599e+00,\n",
            "          7.1764e-01, -2.7893e-01,  3.9713e-01, -5.5112e-01,  8.4296e-01]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 1, 28, 28)"
      ],
      "metadata": {
        "id": "N8-p59603ZOE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "before_relu = x[0][0][0]\n",
        "print(before_relu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE6PMd023o6Q",
        "outputId": "acad8dc5-455f-4b1a-c0ad-44e118d2698e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.8370,  1.7633, -0.0455,  0.1468, -0.4361, -0.5927, -0.1621, -0.9113,\n",
            "         1.1931, -0.7825,  0.0450, -1.8752, -0.0771, -0.2857,  0.3110,  0.7255,\n",
            "        -1.0788,  0.0679,  0.5458, -0.2774,  1.5507,  1.4614,  0.7979,  0.7218,\n",
            "        -1.4168, -0.1721, -0.0814, -1.3554])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relu = nn.ReLU()\n",
        "after_relu = relu(before_relu)\n",
        "print(after_relu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIjhqmLR3sF8",
        "outputId": "640ec4ed-037c-4583-f544-f3ac9968a362"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8370, 1.7633, 0.0000, 0.1468, 0.0000, 0.0000, 0.0000, 0.0000, 1.1931,\n",
            "        0.0000, 0.0450, 0.0000, 0.0000, 0.0000, 0.3110, 0.7255, 0.0000, 0.0679,\n",
            "        0.5458, 0.0000, 1.5507, 1.4614, 0.7979, 0.7218, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1, 10)"
      ],
      "metadata": {
        "id": "mBxqMpGP30Lv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)"
      ],
      "metadata": {
        "id": "HwHhDQvg33jn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = softmax(x)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW_25hly4A5I",
        "outputId": "bdbac0fe-8e64-445b-ec88-562700b6139f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1387, 0.1195, 0.0807, 0.0959, 0.0683, 0.1443, 0.1071, 0.0844, 0.0843,\n",
              "         0.0768]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWhH0Kha4ChM",
        "outputId": "74ae98ea-15a6-467d-943e-a091f1d32d33"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 28*28*1\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6mzsJg44EBx",
        "outputId": "15462f0c-45d2-432b-9ea8-2cae98a8aaac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNet(\n",
            "  (mlp1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (mlp2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        \n",
        "        self.sequential = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.sequential(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "IOu_IFXi4V6H"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 28*28*1\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "\n",
        "model = NeuralNet2(input_size, hidden_size, num_classes).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7lbgXQe5KUP",
        "outputId": "dc402a06-b579-4b82-ea30-f25348eb2580"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNet2(\n",
            "  (sequential): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
            "    (3): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1zgVbLLZ5ejj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}