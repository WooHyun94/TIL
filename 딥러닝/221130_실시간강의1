{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1_NnV4SCtH3FnT2tgiQpKe0wCydaKRHAV","timestamp":1669781217434}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### tf.keras Practice!\n","\n","- CIFAR10 이미지 데이터셋을 분류하는 문제를 풀어봅니다!"],"metadata":{"id":"ZCxzMUXtyuKN"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBHOBxSbvEvC","executionInfo":{"status":"ok","timestamp":1669788132999,"user_tz":-540,"elapsed":782,"user":{"displayName":"우현","userId":"12051300141277122096"}},"outputId":"86ebbd63-2eee-4b01-e4f3-4d739ab75405"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Nov 30 06:02:11 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   70C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZdJiqcQMymOG","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1669788136290,"user_tz":-540,"elapsed":1759,"user":{"displayName":"우현","userId":"12051300141277122096"}},"outputId":"913bb6a1-405d-467e-e218-a78b2ea478ac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.9.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["import tensorflow as tf\n","import numpy as np\n","tf.__version__"]},{"cell_type":"code","source":["# DNN\n","from tensorflow import keras\n","import tensorflow as tf \n","\n","# datasets\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.layers import Input, Dense, Flatten # input layer, connect\n","from tensorflow.keras import Sequential # 순서대로 구현"],"metadata":{"id":"9wbosILfLDe1","executionInfo":{"status":"ok","timestamp":1669788136291,"user_tz":-540,"elapsed":6,"user":{"displayName":"우현","userId":"12051300141277122096"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# load CIFAR10\n","(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"],"metadata":{"id":"kGlnoGn0LcGy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669788136932,"user_tz":-540,"elapsed":646,"user":{"displayName":"우현","userId":"12051300141277122096"}},"outputId":"ddb74d15-9f66-4079-c8f9-1314b3d96716"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"]}]},{"cell_type":"markdown","source":["(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n","- 4차원 tensor \n","    - w: 32, h: 32, RGB -> 50,000장"],"metadata":{"id":"cSDUfG52yG9j"}},{"cell_type":"markdown","source":["### Model Training\n","\n","1. model architecture\n","\n","- Hidden Layer (뒤로 갈수록 hidden node수가 작아짐)\n","\n","- Activation function : 'sigmoid' / 'relu'\n","\n","\n","\n","2. loss optimization\n","\n","\n","- optimizer : 'sgd', 'momentum', 'adam'\n","\n","- batch_size : 1 -> 8-> 32 -> 64 -> 128 -> 256 -> 512 -> 2048 -> ...\n","\n","- epochs : 10 -> 30 -> 100 -> 10000 (overfitting) \n","    - 개념 설명"],"metadata":{"id":"-0jeg5VVey-c"}},{"cell_type":"code","source":["# 모델 구현, Sequential or model()\n","model = Sequential([\n","    Input(shape=(32, 32, 3)),\n","    Flatten(), # 32x32x3 ---> 3072 vector (input layer의 node 수)\n","    Dense(units=1024, activation='relu'),\n","    Dense(units=256, activation='relu'),\n","    Dense(units=128, activation='relu'),\n","    Dense(units=10, activation='softmax') # output layer\n","])\n","\n","\n","model.summary()"],"metadata":{"id":"KMqmYoDXQjw_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669788138982,"user_tz":-540,"elapsed":2052,"user":{"displayName":"우현","userId":"12051300141277122096"}},"outputId":"0560bb31-3bb0-4d84-d08b-d01bd379a525"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           (None, 3072)              0         \n","                                                                 \n"," dense (Dense)               (None, 1024)              3146752   \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               262400    \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               32896     \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 3,443,338\n","Trainable params: 3,443,338\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# compile\n","from tensorflow.keras.optimizers import SGD, Adam\n","\n","lr = 1e-4\n","loss_fn = 'sparse_categorical_crossentropy' # target vector가 정수인 경우. <--> 'categorical_crossentropy' \n","epochs = 200 # 모든 데이터가 학습에 사용되면 1 epoch\n","batch_size = 128\n","#optimizer = SGD(learning_rate=lr) # Learning rate 조절을 위해서 보통 함수로 구현.\n","# optimizer = SGD(learning_rate=lr, momentum=0.9) # Momentum optimizer \n","optimizer = Adam(learning_rate=lr) # Adam optimizer\n","\n","\n","# epochs : 전체 데이터를 몇번 반복 학습을 수행할건지. \n","# iterations : 실제로 weight update를 한 횟수. \n","\n","\n","model.compile(optimizer=optimizer, \n","              loss=loss_fn,\n","              metrics=['accuracy'])"],"metadata":{"id":"YaBGCB67Uunb","executionInfo":{"status":"ok","timestamp":1669788138983,"user_tz":-540,"elapsed":5,"user":{"displayName":"우현","userId":"12051300141277122096"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# fit\n","model.fit(x=X_train,\n","          y=y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=2,\n","          validation_data=(X_test, y_test))"],"metadata":{"id":"NN-gOEGLtkuB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669788401078,"user_tz":-540,"elapsed":262100,"user":{"displayName":"우현","userId":"12051300141277122096"}},"outputId":"6bd6454c-d7e5-449c-819d-b6c8eea93769"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","391/391 - 3s - loss: 11.2802 - accuracy: 0.2385 - val_loss: 5.7327 - val_accuracy: 0.2638 - 3s/epoch - 7ms/step\n","Epoch 2/200\n","391/391 - 1s - loss: 4.3237 - accuracy: 0.2844 - val_loss: 5.1992 - val_accuracy: 0.2617 - 1s/epoch - 4ms/step\n","Epoch 3/200\n","391/391 - 2s - loss: 3.5168 - accuracy: 0.3069 - val_loss: 3.9376 - val_accuracy: 0.2966 - 2s/epoch - 5ms/step\n","Epoch 4/200\n","391/391 - 2s - loss: 3.0618 - accuracy: 0.3305 - val_loss: 3.0335 - val_accuracy: 0.3265 - 2s/epoch - 5ms/step\n","Epoch 5/200\n","391/391 - 2s - loss: 2.8165 - accuracy: 0.3490 - val_loss: 3.1922 - val_accuracy: 0.3555 - 2s/epoch - 4ms/step\n","Epoch 6/200\n","391/391 - 2s - loss: 2.6334 - accuracy: 0.3616 - val_loss: 2.3543 - val_accuracy: 0.3773 - 2s/epoch - 4ms/step\n","Epoch 7/200\n","391/391 - 1s - loss: 2.3242 - accuracy: 0.3858 - val_loss: 2.9919 - val_accuracy: 0.2991 - 1s/epoch - 3ms/step\n","Epoch 8/200\n","391/391 - 1s - loss: 2.1769 - accuracy: 0.3981 - val_loss: 2.3115 - val_accuracy: 0.3979 - 1s/epoch - 3ms/step\n","Epoch 9/200\n","391/391 - 1s - loss: 2.0596 - accuracy: 0.4097 - val_loss: 2.5890 - val_accuracy: 0.3550 - 1s/epoch - 3ms/step\n","Epoch 10/200\n","391/391 - 1s - loss: 1.9970 - accuracy: 0.4185 - val_loss: 2.0067 - val_accuracy: 0.4128 - 1s/epoch - 3ms/step\n","Epoch 11/200\n","391/391 - 1s - loss: 1.9324 - accuracy: 0.4277 - val_loss: 1.9922 - val_accuracy: 0.4180 - 1s/epoch - 3ms/step\n","Epoch 12/200\n","391/391 - 1s - loss: 1.8504 - accuracy: 0.4377 - val_loss: 2.2300 - val_accuracy: 0.3813 - 1s/epoch - 3ms/step\n","Epoch 13/200\n","391/391 - 1s - loss: 1.8259 - accuracy: 0.4431 - val_loss: 2.3619 - val_accuracy: 0.3760 - 1s/epoch - 3ms/step\n","Epoch 14/200\n","391/391 - 1s - loss: 1.7217 - accuracy: 0.4582 - val_loss: 1.9852 - val_accuracy: 0.4088 - 1s/epoch - 3ms/step\n","Epoch 15/200\n","391/391 - 1s - loss: 1.7477 - accuracy: 0.4571 - val_loss: 2.0589 - val_accuracy: 0.3833 - 1s/epoch - 3ms/step\n","Epoch 16/200\n","391/391 - 1s - loss: 1.6554 - accuracy: 0.4733 - val_loss: 1.8424 - val_accuracy: 0.4388 - 1s/epoch - 3ms/step\n","Epoch 17/200\n","391/391 - 1s - loss: 1.5581 - accuracy: 0.4887 - val_loss: 1.7735 - val_accuracy: 0.4423 - 1s/epoch - 3ms/step\n","Epoch 18/200\n","391/391 - 1s - loss: 1.5932 - accuracy: 0.4828 - val_loss: 1.9644 - val_accuracy: 0.4268 - 1s/epoch - 3ms/step\n","Epoch 19/200\n","391/391 - 1s - loss: 1.5551 - accuracy: 0.4889 - val_loss: 2.0939 - val_accuracy: 0.3932 - 1s/epoch - 3ms/step\n","Epoch 20/200\n","391/391 - 1s - loss: 1.4870 - accuracy: 0.5035 - val_loss: 1.8314 - val_accuracy: 0.4313 - 1s/epoch - 3ms/step\n","Epoch 21/200\n","391/391 - 1s - loss: 1.4374 - accuracy: 0.5122 - val_loss: 1.8880 - val_accuracy: 0.4227 - 1s/epoch - 3ms/step\n","Epoch 22/200\n","391/391 - 1s - loss: 1.4741 - accuracy: 0.5086 - val_loss: 1.9023 - val_accuracy: 0.4018 - 1s/epoch - 3ms/step\n","Epoch 23/200\n","391/391 - 1s - loss: 1.3791 - accuracy: 0.5284 - val_loss: 1.6851 - val_accuracy: 0.4638 - 1s/epoch - 3ms/step\n","Epoch 24/200\n","391/391 - 1s - loss: 1.3821 - accuracy: 0.5302 - val_loss: 1.6765 - val_accuracy: 0.4629 - 1s/epoch - 3ms/step\n","Epoch 25/200\n","391/391 - 1s - loss: 1.3341 - accuracy: 0.5423 - val_loss: 1.6407 - val_accuracy: 0.4689 - 1s/epoch - 3ms/step\n","Epoch 26/200\n","391/391 - 1s - loss: 1.3139 - accuracy: 0.5457 - val_loss: 1.7462 - val_accuracy: 0.4361 - 1s/epoch - 3ms/step\n","Epoch 27/200\n","391/391 - 1s - loss: 1.3105 - accuracy: 0.5455 - val_loss: 1.7492 - val_accuracy: 0.4402 - 1s/epoch - 3ms/step\n","Epoch 28/200\n","391/391 - 1s - loss: 1.2689 - accuracy: 0.5591 - val_loss: 1.6253 - val_accuracy: 0.4720 - 1s/epoch - 3ms/step\n","Epoch 29/200\n","391/391 - 1s - loss: 1.2661 - accuracy: 0.5594 - val_loss: 1.6356 - val_accuracy: 0.4632 - 1s/epoch - 3ms/step\n","Epoch 30/200\n","391/391 - 1s - loss: 1.2279 - accuracy: 0.5680 - val_loss: 1.6585 - val_accuracy: 0.4712 - 1s/epoch - 3ms/step\n","Epoch 31/200\n","391/391 - 2s - loss: 1.2049 - accuracy: 0.5789 - val_loss: 1.5949 - val_accuracy: 0.4817 - 2s/epoch - 4ms/step\n","Epoch 32/200\n","391/391 - 2s - loss: 1.1932 - accuracy: 0.5809 - val_loss: 1.6021 - val_accuracy: 0.4741 - 2s/epoch - 4ms/step\n","Epoch 33/200\n","391/391 - 1s - loss: 1.1699 - accuracy: 0.5879 - val_loss: 1.6400 - val_accuracy: 0.4684 - 1s/epoch - 3ms/step\n","Epoch 34/200\n","391/391 - 1s - loss: 1.1456 - accuracy: 0.5972 - val_loss: 1.6462 - val_accuracy: 0.4759 - 1s/epoch - 3ms/step\n","Epoch 35/200\n","391/391 - 1s - loss: 1.1460 - accuracy: 0.5963 - val_loss: 1.6970 - val_accuracy: 0.4660 - 1s/epoch - 3ms/step\n","Epoch 36/200\n","391/391 - 1s - loss: 1.1185 - accuracy: 0.6041 - val_loss: 1.5961 - val_accuracy: 0.4990 - 1s/epoch - 3ms/step\n","Epoch 37/200\n","391/391 - 1s - loss: 1.1165 - accuracy: 0.6061 - val_loss: 1.7341 - val_accuracy: 0.4491 - 1s/epoch - 3ms/step\n","Epoch 38/200\n","391/391 - 1s - loss: 1.0899 - accuracy: 0.6148 - val_loss: 1.6386 - val_accuracy: 0.4810 - 1s/epoch - 3ms/step\n","Epoch 39/200\n","391/391 - 1s - loss: 1.0793 - accuracy: 0.6182 - val_loss: 1.6264 - val_accuracy: 0.4809 - 1s/epoch - 4ms/step\n","Epoch 40/200\n","391/391 - 1s - loss: 1.0736 - accuracy: 0.6191 - val_loss: 1.7058 - val_accuracy: 0.4608 - 1s/epoch - 3ms/step\n","Epoch 41/200\n","391/391 - 1s - loss: 1.0561 - accuracy: 0.6257 - val_loss: 1.6100 - val_accuracy: 0.4773 - 1s/epoch - 3ms/step\n","Epoch 42/200\n","391/391 - 1s - loss: 1.0421 - accuracy: 0.6315 - val_loss: 1.6319 - val_accuracy: 0.4790 - 1s/epoch - 3ms/step\n","Epoch 43/200\n","391/391 - 1s - loss: 1.0331 - accuracy: 0.6340 - val_loss: 1.6148 - val_accuracy: 0.4869 - 1s/epoch - 3ms/step\n","Epoch 44/200\n","391/391 - 1s - loss: 1.0189 - accuracy: 0.6402 - val_loss: 1.6086 - val_accuracy: 0.4990 - 1s/epoch - 3ms/step\n","Epoch 45/200\n","391/391 - 1s - loss: 0.9939 - accuracy: 0.6475 - val_loss: 1.6271 - val_accuracy: 0.4907 - 1s/epoch - 3ms/step\n","Epoch 46/200\n","391/391 - 1s - loss: 0.9781 - accuracy: 0.6558 - val_loss: 1.6691 - val_accuracy: 0.4948 - 1s/epoch - 3ms/step\n","Epoch 47/200\n","391/391 - 1s - loss: 0.9750 - accuracy: 0.6547 - val_loss: 1.6338 - val_accuracy: 0.4989 - 1s/epoch - 3ms/step\n","Epoch 48/200\n","391/391 - 1s - loss: 0.9644 - accuracy: 0.6572 - val_loss: 1.7351 - val_accuracy: 0.4826 - 1s/epoch - 3ms/step\n","Epoch 49/200\n","391/391 - 1s - loss: 0.9575 - accuracy: 0.6598 - val_loss: 1.6462 - val_accuracy: 0.5040 - 1s/epoch - 3ms/step\n","Epoch 50/200\n","391/391 - 1s - loss: 0.9387 - accuracy: 0.6675 - val_loss: 1.6831 - val_accuracy: 0.5035 - 1s/epoch - 3ms/step\n","Epoch 51/200\n","391/391 - 1s - loss: 0.9233 - accuracy: 0.6692 - val_loss: 1.6974 - val_accuracy: 0.4956 - 1s/epoch - 3ms/step\n","Epoch 52/200\n","391/391 - 1s - loss: 0.9044 - accuracy: 0.6799 - val_loss: 1.6854 - val_accuracy: 0.5026 - 1s/epoch - 3ms/step\n","Epoch 53/200\n","391/391 - 1s - loss: 0.8897 - accuracy: 0.6832 - val_loss: 1.6709 - val_accuracy: 0.5081 - 1s/epoch - 3ms/step\n","Epoch 54/200\n","391/391 - 1s - loss: 0.8907 - accuracy: 0.6859 - val_loss: 1.7254 - val_accuracy: 0.4945 - 1s/epoch - 3ms/step\n","Epoch 55/200\n","391/391 - 1s - loss: 0.8845 - accuracy: 0.6868 - val_loss: 1.7347 - val_accuracy: 0.4923 - 1s/epoch - 3ms/step\n","Epoch 56/200\n","391/391 - 1s - loss: 0.8518 - accuracy: 0.6991 - val_loss: 1.7415 - val_accuracy: 0.5020 - 1s/epoch - 3ms/step\n","Epoch 57/200\n","391/391 - 1s - loss: 0.8476 - accuracy: 0.6995 - val_loss: 1.8132 - val_accuracy: 0.4868 - 1s/epoch - 3ms/step\n","Epoch 58/200\n","391/391 - 1s - loss: 0.8367 - accuracy: 0.7028 - val_loss: 1.7898 - val_accuracy: 0.4924 - 1s/epoch - 3ms/step\n","Epoch 59/200\n","391/391 - 1s - loss: 0.8177 - accuracy: 0.7109 - val_loss: 1.8390 - val_accuracy: 0.4936 - 1s/epoch - 3ms/step\n","Epoch 60/200\n","391/391 - 1s - loss: 0.8257 - accuracy: 0.7054 - val_loss: 1.7884 - val_accuracy: 0.4963 - 1s/epoch - 3ms/step\n","Epoch 61/200\n","391/391 - 1s - loss: 0.7959 - accuracy: 0.7194 - val_loss: 1.7990 - val_accuracy: 0.4931 - 1s/epoch - 3ms/step\n","Epoch 62/200\n","391/391 - 1s - loss: 0.7885 - accuracy: 0.7219 - val_loss: 1.8690 - val_accuracy: 0.4958 - 1s/epoch - 3ms/step\n","Epoch 63/200\n","391/391 - 1s - loss: 0.7887 - accuracy: 0.7207 - val_loss: 1.8777 - val_accuracy: 0.4917 - 1s/epoch - 3ms/step\n","Epoch 64/200\n","391/391 - 1s - loss: 0.7783 - accuracy: 0.7245 - val_loss: 1.8477 - val_accuracy: 0.4937 - 1s/epoch - 3ms/step\n","Epoch 65/200\n","391/391 - 1s - loss: 0.7557 - accuracy: 0.7310 - val_loss: 1.9160 - val_accuracy: 0.4914 - 1s/epoch - 3ms/step\n","Epoch 66/200\n","391/391 - 1s - loss: 0.7427 - accuracy: 0.7350 - val_loss: 1.8421 - val_accuracy: 0.5061 - 1s/epoch - 3ms/step\n","Epoch 67/200\n","391/391 - 1s - loss: 0.7322 - accuracy: 0.7413 - val_loss: 1.9034 - val_accuracy: 0.5045 - 1s/epoch - 3ms/step\n","Epoch 68/200\n","391/391 - 1s - loss: 0.7234 - accuracy: 0.7436 - val_loss: 1.9544 - val_accuracy: 0.4815 - 1s/epoch - 3ms/step\n","Epoch 69/200\n","391/391 - 1s - loss: 0.7436 - accuracy: 0.7369 - val_loss: 1.9081 - val_accuracy: 0.5063 - 1s/epoch - 3ms/step\n","Epoch 70/200\n","391/391 - 1s - loss: 0.7010 - accuracy: 0.7528 - val_loss: 1.9500 - val_accuracy: 0.4922 - 1s/epoch - 3ms/step\n","Epoch 71/200\n","391/391 - 1s - loss: 0.6911 - accuracy: 0.7550 - val_loss: 1.9664 - val_accuracy: 0.4969 - 1s/epoch - 3ms/step\n","Epoch 72/200\n","391/391 - 1s - loss: 0.6874 - accuracy: 0.7573 - val_loss: 2.0032 - val_accuracy: 0.4946 - 1s/epoch - 3ms/step\n","Epoch 73/200\n","391/391 - 1s - loss: 0.6790 - accuracy: 0.7607 - val_loss: 2.0385 - val_accuracy: 0.4899 - 1s/epoch - 3ms/step\n","Epoch 74/200\n","391/391 - 1s - loss: 0.6642 - accuracy: 0.7650 - val_loss: 1.9823 - val_accuracy: 0.5041 - 1s/epoch - 3ms/step\n","Epoch 75/200\n","391/391 - 1s - loss: 0.6477 - accuracy: 0.7715 - val_loss: 1.9619 - val_accuracy: 0.5040 - 1s/epoch - 3ms/step\n","Epoch 76/200\n","391/391 - 1s - loss: 0.6357 - accuracy: 0.7748 - val_loss: 2.0390 - val_accuracy: 0.5029 - 1s/epoch - 3ms/step\n","Epoch 77/200\n","391/391 - 1s - loss: 0.6471 - accuracy: 0.7703 - val_loss: 2.0750 - val_accuracy: 0.5111 - 1s/epoch - 3ms/step\n","Epoch 78/200\n","391/391 - 1s - loss: 0.6209 - accuracy: 0.7819 - val_loss: 2.1399 - val_accuracy: 0.5000 - 1s/epoch - 3ms/step\n","Epoch 79/200\n","391/391 - 1s - loss: 0.6234 - accuracy: 0.7779 - val_loss: 2.1422 - val_accuracy: 0.4961 - 1s/epoch - 3ms/step\n","Epoch 80/200\n","391/391 - 1s - loss: 0.6058 - accuracy: 0.7881 - val_loss: 2.0850 - val_accuracy: 0.5040 - 1s/epoch - 4ms/step\n","Epoch 81/200\n","391/391 - 1s - loss: 0.5956 - accuracy: 0.7900 - val_loss: 2.2271 - val_accuracy: 0.4928 - 1s/epoch - 3ms/step\n","Epoch 82/200\n","391/391 - 1s - loss: 0.5863 - accuracy: 0.7934 - val_loss: 2.1510 - val_accuracy: 0.4980 - 1s/epoch - 3ms/step\n","Epoch 83/200\n","391/391 - 1s - loss: 0.5907 - accuracy: 0.7908 - val_loss: 2.2884 - val_accuracy: 0.4861 - 1s/epoch - 3ms/step\n","Epoch 84/200\n","391/391 - 1s - loss: 0.5908 - accuracy: 0.7917 - val_loss: 2.1862 - val_accuracy: 0.4992 - 1s/epoch - 3ms/step\n","Epoch 85/200\n","391/391 - 1s - loss: 0.5675 - accuracy: 0.7997 - val_loss: 2.1756 - val_accuracy: 0.5047 - 1s/epoch - 3ms/step\n","Epoch 86/200\n","391/391 - 1s - loss: 0.5653 - accuracy: 0.8030 - val_loss: 2.2228 - val_accuracy: 0.4963 - 1s/epoch - 3ms/step\n","Epoch 87/200\n","391/391 - 1s - loss: 0.5533 - accuracy: 0.8052 - val_loss: 2.2730 - val_accuracy: 0.4873 - 1s/epoch - 3ms/step\n","Epoch 88/200\n","391/391 - 1s - loss: 0.5446 - accuracy: 0.8077 - val_loss: 2.3484 - val_accuracy: 0.4986 - 1s/epoch - 3ms/step\n","Epoch 89/200\n","391/391 - 1s - loss: 0.5526 - accuracy: 0.8059 - val_loss: 2.2636 - val_accuracy: 0.4971 - 1s/epoch - 3ms/step\n","Epoch 90/200\n","391/391 - 1s - loss: 0.5270 - accuracy: 0.8139 - val_loss: 2.2878 - val_accuracy: 0.5010 - 1s/epoch - 3ms/step\n","Epoch 91/200\n","391/391 - 1s - loss: 0.5277 - accuracy: 0.8126 - val_loss: 2.4091 - val_accuracy: 0.4964 - 1s/epoch - 3ms/step\n","Epoch 92/200\n","391/391 - 1s - loss: 0.5166 - accuracy: 0.8180 - val_loss: 2.3280 - val_accuracy: 0.5104 - 1s/epoch - 3ms/step\n","Epoch 93/200\n","391/391 - 1s - loss: 0.5109 - accuracy: 0.8193 - val_loss: 2.3030 - val_accuracy: 0.5048 - 1s/epoch - 3ms/step\n","Epoch 94/200\n","391/391 - 1s - loss: 0.5017 - accuracy: 0.8241 - val_loss: 2.4772 - val_accuracy: 0.4976 - 1s/epoch - 3ms/step\n","Epoch 95/200\n","391/391 - 1s - loss: 0.4878 - accuracy: 0.8282 - val_loss: 2.3454 - val_accuracy: 0.5085 - 1s/epoch - 3ms/step\n","Epoch 96/200\n","391/391 - 1s - loss: 0.4820 - accuracy: 0.8302 - val_loss: 2.4638 - val_accuracy: 0.4982 - 1s/epoch - 3ms/step\n","Epoch 97/200\n","391/391 - 1s - loss: 0.4779 - accuracy: 0.8305 - val_loss: 2.5401 - val_accuracy: 0.4917 - 1s/epoch - 3ms/step\n","Epoch 98/200\n","391/391 - 1s - loss: 0.4948 - accuracy: 0.8244 - val_loss: 2.5298 - val_accuracy: 0.5064 - 1s/epoch - 3ms/step\n","Epoch 99/200\n","391/391 - 1s - loss: 0.4823 - accuracy: 0.8300 - val_loss: 2.4211 - val_accuracy: 0.4999 - 1s/epoch - 3ms/step\n","Epoch 100/200\n","391/391 - 1s - loss: 0.4648 - accuracy: 0.8363 - val_loss: 2.5679 - val_accuracy: 0.4963 - 1s/epoch - 3ms/step\n","Epoch 101/200\n","391/391 - 1s - loss: 0.4530 - accuracy: 0.8398 - val_loss: 2.5135 - val_accuracy: 0.5003 - 1s/epoch - 3ms/step\n","Epoch 102/200\n","391/391 - 1s - loss: 0.4569 - accuracy: 0.8404 - val_loss: 2.5584 - val_accuracy: 0.5054 - 1s/epoch - 3ms/step\n","Epoch 103/200\n","391/391 - 1s - loss: 0.4477 - accuracy: 0.8445 - val_loss: 2.5488 - val_accuracy: 0.5048 - 1s/epoch - 3ms/step\n","Epoch 104/200\n","391/391 - 1s - loss: 0.4410 - accuracy: 0.8458 - val_loss: 2.6328 - val_accuracy: 0.4955 - 1s/epoch - 3ms/step\n","Epoch 105/200\n","391/391 - 1s - loss: 0.4320 - accuracy: 0.8480 - val_loss: 2.6369 - val_accuracy: 0.4874 - 1s/epoch - 3ms/step\n","Epoch 106/200\n","391/391 - 1s - loss: 0.4361 - accuracy: 0.8451 - val_loss: 2.5831 - val_accuracy: 0.4976 - 1s/epoch - 3ms/step\n","Epoch 107/200\n","391/391 - 1s - loss: 0.4232 - accuracy: 0.8504 - val_loss: 2.7004 - val_accuracy: 0.4921 - 1s/epoch - 3ms/step\n","Epoch 108/200\n","391/391 - 1s - loss: 0.4254 - accuracy: 0.8504 - val_loss: 2.7912 - val_accuracy: 0.4918 - 1s/epoch - 3ms/step\n","Epoch 109/200\n","391/391 - 1s - loss: 0.4018 - accuracy: 0.8598 - val_loss: 2.7088 - val_accuracy: 0.5023 - 1s/epoch - 3ms/step\n","Epoch 110/200\n","391/391 - 1s - loss: 0.3978 - accuracy: 0.8596 - val_loss: 2.7300 - val_accuracy: 0.4919 - 1s/epoch - 3ms/step\n","Epoch 111/200\n","391/391 - 1s - loss: 0.4056 - accuracy: 0.8577 - val_loss: 2.8095 - val_accuracy: 0.4928 - 1s/epoch - 3ms/step\n","Epoch 112/200\n","391/391 - 1s - loss: 0.4072 - accuracy: 0.8553 - val_loss: 2.7449 - val_accuracy: 0.5025 - 1s/epoch - 3ms/step\n","Epoch 113/200\n","391/391 - 1s - loss: 0.4080 - accuracy: 0.8583 - val_loss: 2.7663 - val_accuracy: 0.4996 - 1s/epoch - 3ms/step\n","Epoch 114/200\n","391/391 - 1s - loss: 0.3961 - accuracy: 0.8598 - val_loss: 2.8251 - val_accuracy: 0.5002 - 1s/epoch - 3ms/step\n","Epoch 115/200\n","391/391 - 1s - loss: 0.3755 - accuracy: 0.8686 - val_loss: 2.9367 - val_accuracy: 0.4868 - 1s/epoch - 3ms/step\n","Epoch 116/200\n","391/391 - 1s - loss: 0.3799 - accuracy: 0.8658 - val_loss: 2.9749 - val_accuracy: 0.4902 - 1s/epoch - 3ms/step\n","Epoch 117/200\n","391/391 - 1s - loss: 0.3711 - accuracy: 0.8689 - val_loss: 2.9428 - val_accuracy: 0.4985 - 1s/epoch - 3ms/step\n","Epoch 118/200\n","391/391 - 1s - loss: 0.3815 - accuracy: 0.8652 - val_loss: 2.8833 - val_accuracy: 0.5014 - 1s/epoch - 3ms/step\n","Epoch 119/200\n","391/391 - 1s - loss: 0.3731 - accuracy: 0.8685 - val_loss: 2.8382 - val_accuracy: 0.5057 - 1s/epoch - 3ms/step\n","Epoch 120/200\n","391/391 - 1s - loss: 0.3477 - accuracy: 0.8773 - val_loss: 2.9684 - val_accuracy: 0.4953 - 1s/epoch - 3ms/step\n","Epoch 121/200\n","391/391 - 1s - loss: 0.3605 - accuracy: 0.8713 - val_loss: 2.9753 - val_accuracy: 0.5036 - 1s/epoch - 3ms/step\n","Epoch 122/200\n","391/391 - 1s - loss: 0.3516 - accuracy: 0.8772 - val_loss: 3.0727 - val_accuracy: 0.4965 - 1s/epoch - 3ms/step\n","Epoch 123/200\n","391/391 - 1s - loss: 0.3596 - accuracy: 0.8723 - val_loss: 2.9733 - val_accuracy: 0.4974 - 1s/epoch - 3ms/step\n","Epoch 124/200\n","391/391 - 1s - loss: 0.3511 - accuracy: 0.8773 - val_loss: 2.9708 - val_accuracy: 0.4972 - 1s/epoch - 3ms/step\n","Epoch 125/200\n","391/391 - 1s - loss: 0.3350 - accuracy: 0.8814 - val_loss: 3.1865 - val_accuracy: 0.4845 - 1s/epoch - 3ms/step\n","Epoch 126/200\n","391/391 - 1s - loss: 0.3493 - accuracy: 0.8779 - val_loss: 2.9532 - val_accuracy: 0.5000 - 1s/epoch - 3ms/step\n","Epoch 127/200\n","391/391 - 1s - loss: 0.3347 - accuracy: 0.8837 - val_loss: 3.1016 - val_accuracy: 0.4948 - 1s/epoch - 3ms/step\n","Epoch 128/200\n","391/391 - 1s - loss: 0.3248 - accuracy: 0.8856 - val_loss: 3.0481 - val_accuracy: 0.5098 - 1s/epoch - 3ms/step\n","Epoch 129/200\n","391/391 - 1s - loss: 0.3311 - accuracy: 0.8849 - val_loss: 3.1644 - val_accuracy: 0.4882 - 1s/epoch - 3ms/step\n","Epoch 130/200\n","391/391 - 1s - loss: 0.3199 - accuracy: 0.8884 - val_loss: 3.1704 - val_accuracy: 0.4906 - 1s/epoch - 3ms/step\n","Epoch 131/200\n","391/391 - 1s - loss: 0.3207 - accuracy: 0.8882 - val_loss: 3.1170 - val_accuracy: 0.5022 - 1s/epoch - 3ms/step\n","Epoch 132/200\n","391/391 - 1s - loss: 0.3094 - accuracy: 0.8911 - val_loss: 3.2199 - val_accuracy: 0.4973 - 1s/epoch - 3ms/step\n","Epoch 133/200\n","391/391 - 1s - loss: 0.3260 - accuracy: 0.8842 - val_loss: 3.2514 - val_accuracy: 0.4969 - 1s/epoch - 3ms/step\n","Epoch 134/200\n","391/391 - 1s - loss: 0.3074 - accuracy: 0.8918 - val_loss: 3.2612 - val_accuracy: 0.4854 - 1s/epoch - 3ms/step\n","Epoch 135/200\n","391/391 - 1s - loss: 0.3032 - accuracy: 0.8926 - val_loss: 3.2932 - val_accuracy: 0.4939 - 1s/epoch - 4ms/step\n","Epoch 136/200\n","391/391 - 1s - loss: 0.3001 - accuracy: 0.8947 - val_loss: 3.3201 - val_accuracy: 0.4945 - 1s/epoch - 3ms/step\n","Epoch 137/200\n","391/391 - 1s - loss: 0.3131 - accuracy: 0.8913 - val_loss: 3.4573 - val_accuracy: 0.4905 - 1s/epoch - 3ms/step\n","Epoch 138/200\n","391/391 - 1s - loss: 0.2946 - accuracy: 0.8971 - val_loss: 3.4385 - val_accuracy: 0.4931 - 1s/epoch - 3ms/step\n","Epoch 139/200\n","391/391 - 1s - loss: 0.2789 - accuracy: 0.9022 - val_loss: 3.2984 - val_accuracy: 0.5044 - 1s/epoch - 3ms/step\n","Epoch 140/200\n","391/391 - 1s - loss: 0.3083 - accuracy: 0.8898 - val_loss: 3.3965 - val_accuracy: 0.5011 - 1s/epoch - 3ms/step\n","Epoch 141/200\n","391/391 - 1s - loss: 0.2871 - accuracy: 0.8977 - val_loss: 3.4748 - val_accuracy: 0.4937 - 1s/epoch - 3ms/step\n","Epoch 142/200\n","391/391 - 1s - loss: 0.2674 - accuracy: 0.9062 - val_loss: 3.3472 - val_accuracy: 0.5023 - 1s/epoch - 3ms/step\n","Epoch 143/200\n","391/391 - 1s - loss: 0.2986 - accuracy: 0.8946 - val_loss: 3.4746 - val_accuracy: 0.4933 - 1s/epoch - 3ms/step\n","Epoch 144/200\n","391/391 - 1s - loss: 0.2973 - accuracy: 0.8960 - val_loss: 3.4104 - val_accuracy: 0.4981 - 1s/epoch - 3ms/step\n","Epoch 145/200\n","391/391 - 1s - loss: 0.2621 - accuracy: 0.9084 - val_loss: 3.5490 - val_accuracy: 0.4953 - 1s/epoch - 3ms/step\n","Epoch 146/200\n","391/391 - 1s - loss: 0.2702 - accuracy: 0.9055 - val_loss: 3.4537 - val_accuracy: 0.4991 - 1s/epoch - 3ms/step\n","Epoch 147/200\n","391/391 - 1s - loss: 0.2814 - accuracy: 0.9003 - val_loss: 3.3863 - val_accuracy: 0.4988 - 1s/epoch - 3ms/step\n","Epoch 148/200\n","391/391 - 1s - loss: 0.2602 - accuracy: 0.9094 - val_loss: 3.5988 - val_accuracy: 0.4905 - 1s/epoch - 3ms/step\n","Epoch 149/200\n","391/391 - 1s - loss: 0.2784 - accuracy: 0.9032 - val_loss: 3.6245 - val_accuracy: 0.4979 - 1s/epoch - 3ms/step\n","Epoch 150/200\n","391/391 - 1s - loss: 0.2568 - accuracy: 0.9098 - val_loss: 3.5267 - val_accuracy: 0.4918 - 1s/epoch - 3ms/step\n","Epoch 151/200\n","391/391 - 1s - loss: 0.2594 - accuracy: 0.9095 - val_loss: 3.6485 - val_accuracy: 0.4897 - 1s/epoch - 3ms/step\n","Epoch 152/200\n","391/391 - 1s - loss: 0.2646 - accuracy: 0.9056 - val_loss: 3.5962 - val_accuracy: 0.4976 - 1s/epoch - 3ms/step\n","Epoch 153/200\n","391/391 - 1s - loss: 0.2628 - accuracy: 0.9090 - val_loss: 3.5962 - val_accuracy: 0.4902 - 1s/epoch - 3ms/step\n","Epoch 154/200\n","391/391 - 1s - loss: 0.2427 - accuracy: 0.9151 - val_loss: 3.6094 - val_accuracy: 0.5039 - 1s/epoch - 3ms/step\n","Epoch 155/200\n","391/391 - 1s - loss: 0.2291 - accuracy: 0.9209 - val_loss: 3.6234 - val_accuracy: 0.4984 - 1s/epoch - 3ms/step\n","Epoch 156/200\n","391/391 - 1s - loss: 0.2535 - accuracy: 0.9118 - val_loss: 3.6743 - val_accuracy: 0.4936 - 1s/epoch - 3ms/step\n","Epoch 157/200\n","391/391 - 1s - loss: 0.2472 - accuracy: 0.9139 - val_loss: 3.7794 - val_accuracy: 0.4927 - 1s/epoch - 3ms/step\n","Epoch 158/200\n","391/391 - 1s - loss: 0.2649 - accuracy: 0.9070 - val_loss: 3.8383 - val_accuracy: 0.4909 - 1s/epoch - 3ms/step\n","Epoch 159/200\n","391/391 - 1s - loss: 0.2359 - accuracy: 0.9184 - val_loss: 3.6885 - val_accuracy: 0.5030 - 1s/epoch - 3ms/step\n","Epoch 160/200\n","391/391 - 1s - loss: 0.2284 - accuracy: 0.9206 - val_loss: 3.7916 - val_accuracy: 0.5004 - 1s/epoch - 3ms/step\n","Epoch 161/200\n","391/391 - 1s - loss: 0.2592 - accuracy: 0.9101 - val_loss: 3.8817 - val_accuracy: 0.4913 - 1s/epoch - 3ms/step\n","Epoch 162/200\n","391/391 - 1s - loss: 0.2411 - accuracy: 0.9162 - val_loss: 3.8363 - val_accuracy: 0.5000 - 1s/epoch - 3ms/step\n","Epoch 163/200\n","391/391 - 1s - loss: 0.2123 - accuracy: 0.9269 - val_loss: 3.7390 - val_accuracy: 0.4937 - 1s/epoch - 3ms/step\n","Epoch 164/200\n","391/391 - 1s - loss: 0.2512 - accuracy: 0.9124 - val_loss: 3.9366 - val_accuracy: 0.4870 - 1s/epoch - 3ms/step\n","Epoch 165/200\n","391/391 - 1s - loss: 0.2380 - accuracy: 0.9178 - val_loss: 3.8744 - val_accuracy: 0.4945 - 1s/epoch - 3ms/step\n","Epoch 166/200\n","391/391 - 1s - loss: 0.2057 - accuracy: 0.9289 - val_loss: 3.9611 - val_accuracy: 0.4948 - 1s/epoch - 3ms/step\n","Epoch 167/200\n","391/391 - 1s - loss: 0.2385 - accuracy: 0.9150 - val_loss: 3.9728 - val_accuracy: 0.4945 - 1s/epoch - 3ms/step\n","Epoch 168/200\n","391/391 - 1s - loss: 0.2168 - accuracy: 0.9238 - val_loss: 3.9519 - val_accuracy: 0.5055 - 1s/epoch - 3ms/step\n","Epoch 169/200\n","391/391 - 1s - loss: 0.2140 - accuracy: 0.9249 - val_loss: 3.9321 - val_accuracy: 0.5003 - 1s/epoch - 3ms/step\n","Epoch 170/200\n","391/391 - 1s - loss: 0.2237 - accuracy: 0.9220 - val_loss: 3.9902 - val_accuracy: 0.4867 - 1s/epoch - 3ms/step\n","Epoch 171/200\n","391/391 - 1s - loss: 0.2193 - accuracy: 0.9223 - val_loss: 3.8983 - val_accuracy: 0.4939 - 1s/epoch - 3ms/step\n","Epoch 172/200\n","391/391 - 1s - loss: 0.2274 - accuracy: 0.9195 - val_loss: 4.1146 - val_accuracy: 0.4828 - 1s/epoch - 3ms/step\n","Epoch 173/200\n","391/391 - 1s - loss: 0.2296 - accuracy: 0.9210 - val_loss: 4.0271 - val_accuracy: 0.4890 - 1s/epoch - 3ms/step\n","Epoch 174/200\n","391/391 - 1s - loss: 0.1933 - accuracy: 0.9319 - val_loss: 4.1845 - val_accuracy: 0.4919 - 1s/epoch - 3ms/step\n","Epoch 175/200\n","391/391 - 1s - loss: 0.2160 - accuracy: 0.9242 - val_loss: 4.0514 - val_accuracy: 0.4925 - 1s/epoch - 3ms/step\n","Epoch 176/200\n","391/391 - 1s - loss: 0.2013 - accuracy: 0.9297 - val_loss: 3.9531 - val_accuracy: 0.5063 - 1s/epoch - 3ms/step\n","Epoch 177/200\n","391/391 - 1s - loss: 0.2244 - accuracy: 0.9214 - val_loss: 3.9731 - val_accuracy: 0.4943 - 1s/epoch - 3ms/step\n","Epoch 178/200\n","391/391 - 1s - loss: 0.2173 - accuracy: 0.9233 - val_loss: 4.2495 - val_accuracy: 0.4894 - 1s/epoch - 3ms/step\n","Epoch 179/200\n","391/391 - 1s - loss: 0.1970 - accuracy: 0.9311 - val_loss: 4.0265 - val_accuracy: 0.4902 - 1s/epoch - 3ms/step\n","Epoch 180/200\n","391/391 - 1s - loss: 0.1937 - accuracy: 0.9337 - val_loss: 4.1792 - val_accuracy: 0.4892 - 1s/epoch - 3ms/step\n","Epoch 181/200\n","391/391 - 1s - loss: 0.2296 - accuracy: 0.9205 - val_loss: 4.0799 - val_accuracy: 0.4983 - 1s/epoch - 4ms/step\n","Epoch 182/200\n","391/391 - 2s - loss: 0.1863 - accuracy: 0.9334 - val_loss: 4.2453 - val_accuracy: 0.4830 - 2s/epoch - 4ms/step\n","Epoch 183/200\n","391/391 - 1s - loss: 0.1865 - accuracy: 0.9351 - val_loss: 4.1336 - val_accuracy: 0.4980 - 1s/epoch - 3ms/step\n","Epoch 184/200\n","391/391 - 1s - loss: 0.2067 - accuracy: 0.9275 - val_loss: 4.2994 - val_accuracy: 0.4953 - 1s/epoch - 3ms/step\n","Epoch 185/200\n","391/391 - 1s - loss: 0.2068 - accuracy: 0.9281 - val_loss: 4.1713 - val_accuracy: 0.4985 - 1s/epoch - 3ms/step\n","Epoch 186/200\n","391/391 - 1s - loss: 0.1809 - accuracy: 0.9375 - val_loss: 4.2370 - val_accuracy: 0.4990 - 1s/epoch - 3ms/step\n","Epoch 187/200\n","391/391 - 1s - loss: 0.2034 - accuracy: 0.9299 - val_loss: 4.1655 - val_accuracy: 0.5011 - 1s/epoch - 3ms/step\n","Epoch 188/200\n","391/391 - 1s - loss: 0.2001 - accuracy: 0.9300 - val_loss: 4.3074 - val_accuracy: 0.4849 - 1s/epoch - 3ms/step\n","Epoch 189/200\n","391/391 - 1s - loss: 0.1852 - accuracy: 0.9368 - val_loss: 4.3735 - val_accuracy: 0.4953 - 1s/epoch - 3ms/step\n","Epoch 190/200\n","391/391 - 1s - loss: 0.1893 - accuracy: 0.9333 - val_loss: 4.3052 - val_accuracy: 0.4951 - 1s/epoch - 3ms/step\n","Epoch 191/200\n","391/391 - 1s - loss: 0.1679 - accuracy: 0.9421 - val_loss: 4.3141 - val_accuracy: 0.5066 - 1s/epoch - 3ms/step\n","Epoch 192/200\n","391/391 - 1s - loss: 0.2177 - accuracy: 0.9233 - val_loss: 4.2997 - val_accuracy: 0.4981 - 1s/epoch - 3ms/step\n","Epoch 193/200\n","391/391 - 1s - loss: 0.1784 - accuracy: 0.9380 - val_loss: 4.4515 - val_accuracy: 0.5014 - 1s/epoch - 3ms/step\n","Epoch 194/200\n","391/391 - 1s - loss: 0.1717 - accuracy: 0.9408 - val_loss: 4.3966 - val_accuracy: 0.4914 - 1s/epoch - 3ms/step\n","Epoch 195/200\n","391/391 - 1s - loss: 0.1930 - accuracy: 0.9328 - val_loss: 4.4735 - val_accuracy: 0.4903 - 1s/epoch - 3ms/step\n","Epoch 196/200\n","391/391 - 1s - loss: 0.1732 - accuracy: 0.9391 - val_loss: 4.3563 - val_accuracy: 0.4941 - 1s/epoch - 3ms/step\n","Epoch 197/200\n","391/391 - 1s - loss: 0.2063 - accuracy: 0.9284 - val_loss: 4.3396 - val_accuracy: 0.4957 - 1s/epoch - 3ms/step\n","Epoch 198/200\n","391/391 - 1s - loss: 0.1840 - accuracy: 0.9360 - val_loss: 4.4784 - val_accuracy: 0.4897 - 1s/epoch - 3ms/step\n","Epoch 199/200\n","391/391 - 1s - loss: 0.1600 - accuracy: 0.9449 - val_loss: 4.4714 - val_accuracy: 0.4883 - 1s/epoch - 3ms/step\n","Epoch 200/200\n","391/391 - 1s - loss: 0.1642 - accuracy: 0.9425 - val_loss: 4.5224 - val_accuracy: 0.4920 - 1s/epoch - 3ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f73504fef90>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# evaluate\n","loss, acc = model.evaluate(X_test, y_test, batch_size)\n","print(\"Loss : %.4f, Test Accuracy : %.4f\" % (loss, acc))\n","\n","## 어떤 Hyper-parameter setting에서 최고의 성능이 나왔나요?\n"],"metadata":{"id":"mb0Z9y8RkAUN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669788401079,"user_tz":-540,"elapsed":16,"user":{"displayName":"우현","userId":"12051300141277122096"}},"outputId":"2142ac01-9b53-4730-c5ab-e7d86502bca8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["79/79 [==============================] - 0s 3ms/step - loss: 4.5224 - accuracy: 0.4920\n","Loss : 4.5224, Test Accuracy : 0.4920\n"]}]},{"cell_type":"code","source":["# 언더 피팅 - 모델 바꾸기 \n","# 오버 피팅 - 배치 사이즈 등 바꾸기"],"metadata":{"id":"1OB7BnIx9zOT","executionInfo":{"status":"ok","timestamp":1669788401079,"user_tz":-540,"elapsed":4,"user":{"displayName":"우현","userId":"12051300141277122096"}}},"execution_count":9,"outputs":[]}]}